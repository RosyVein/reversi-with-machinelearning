{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2_1zKlBhaVO",
        "outputId": "332d7b34-b26a-4555-83d0-0c0b69fe07a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting creversi\n",
            "  Downloading creversi-0.0.1-cp310-cp310-manylinux_2_24_x86_64.whl (711 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m711.0/711.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: creversi\n",
            "Successfully installed creversi-0.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install creversi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvIxe8ZWK_9r",
        "outputId": "cd6c4ecc-2fad-41fb-deb1-314d5316429e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/creversi/__init__.py:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from .creversi import *\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import creversi.gym_reversi\n",
        "from creversi import *\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import datetime\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from IPython.display import display, SVG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJl6Yit6hVcX",
        "outputId": "54c38a92-c9a9-41cd-896e-2ad677baf878"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (8, 8)\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-12-23 03:58:52 DEBUG Initializing MLIR with module: _site_initialize_0\n",
            "2023-12-23 03:58:52 DEBUG Registering dialects from initializer <module 'jaxlib.mlir._mlir_libs._site_initialize_0' from '/usr/local/lib/python3.10/dist-packages/jaxlib/mlir/_mlir_libs/_site_initialize_0.so'>\n",
            "2023-12-23 03:58:52 DEBUG etils.epath found. Using etils.epath for file I/O.\n"
          ]
        }
      ],
      "source": [
        "resume = ''\n",
        "logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s', datefmt='%Y-%m-%d %H:%M:%S', stream=sys.stdout, level=logging.DEBUG, force=True)\n",
        "\n",
        "env = gym.make('Reversi-v0').unwrapped\n",
        "\n",
        "# if gpu is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "######################################################################\n",
        "# Replay Memory\n",
        "\n",
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'next_actions', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# DQN\n",
        "\n",
        "k = 192\n",
        "fcl_units = 256\n",
        "class DQN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DQN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(2, k, kernel_size=3, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(k)\n",
        "    self.conv2 = nn.Conv2d(k, k, kernel_size=3, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(k)\n",
        "    self.conv3 = nn.Conv2d(k, k, kernel_size=3, padding=1)\n",
        "    self.bn3 = nn.BatchNorm2d(k)\n",
        "    self.conv4 = nn.Conv2d(k, k, kernel_size=3, padding=1)\n",
        "    self.bn4 = nn.BatchNorm2d(k)\n",
        "    self.conv5 = nn.Conv2d(k, k, kernel_size=3, padding=1)\n",
        "    self.bn5 = nn.BatchNorm2d(k)\n",
        "    self.conv6 = nn.Conv2d(k, k, kernel_size=3, padding=1)\n",
        "    self.bn6 = nn.BatchNorm2d(k)\n",
        "    self.conv7 = nn.Conv2d(k, k, kernel_size=3, padding=1)\n",
        "    self.bn7 = nn.BatchNorm2d(k)\n",
        "    self.conv8 = nn.Conv2d(k, k, kernel_size=3, padding=1)\n",
        "    self.bn8 = nn.BatchNorm2d(k)\n",
        "    self.conv9 = nn.Conv2d(k, k, kernel_size=3, padding=1)\n",
        "    self.bn9 = nn.BatchNorm2d(k)\n",
        "    self.conv10 = nn.Conv2d(k, k, kernel_size=3, padding=1)\n",
        "    self.bn10 = nn.BatchNorm2d(k)\n",
        "    self.fcl1 = nn.Linear(k * 64, fcl_units)\n",
        "    self.fcl2 = nn.Linear(fcl_units, 65)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.relu(self.bn3(self.conv3(x)))\n",
        "    x = F.relu(self.bn4(self.conv4(x)))\n",
        "    x = F.relu(self.bn5(self.conv5(x)))\n",
        "    x = F.relu(self.bn6(self.conv6(x)))\n",
        "    x = F.relu(self.bn7(self.conv7(x)))\n",
        "    x = F.relu(self.bn8(self.conv8(x)))\n",
        "    x = F.relu(self.bn9(self.conv9(x)))\n",
        "    x = F.relu(self.bn10(self.conv10(x)))\n",
        "    x = F.relu(self.fcl1(x.view(-1, k * 64)))\n",
        "    x = self.fcl2(x)\n",
        "    return x.tanh()\n",
        "\n",
        "def get_state(board):\n",
        "    features = np.empty((1, 2, 8, 8), dtype=np.float32)\n",
        "    board.piece_planes(features[0])\n",
        "    state = torch.from_numpy(features[:1]).to(device)\n",
        "    return state\n",
        "\n",
        "######################################################################\n",
        "# Training\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 2000\n",
        "OPTIMIZE_PER_EPISODES = 16\n",
        "TARGET_UPDATE = 4\n",
        "\n",
        "policy_net = DQN().to(device)\n",
        "target_net = DQN().to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.RMSprop(policy_net.parameters(), lr=1e-5)\n",
        "\n",
        "if resume:\n",
        "    print('resume {}'.format(resume))\n",
        "    checkpoint = torch.load(resume)\n",
        "    target_net.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "memory = ReplayMemory(131072)\n",
        "\n",
        "def epsilon_greedy(state, legal_moves):\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * episodes_done / EPS_DECAY)\n",
        "\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            q = policy_net(state)\n",
        "            _, select = q[0, legal_moves].max(0)\n",
        "    else:\n",
        "        select = random.randrange(len(legal_moves))\n",
        "    return select\n",
        "\n",
        "temperature = 0.5\n",
        "def softmax(state, legal_moves):\n",
        "    with torch.no_grad():\n",
        "        q = policy_net(state)\n",
        "        log_prob = q[0, legal_moves] / temperature\n",
        "        select = torch.distributions.categorical.Categorical(logits=log_prob).sample()\n",
        "    return select\n",
        "\n",
        "def select_action(state, board):\n",
        "\n",
        "    legal_moves = list(board.legal_moves)\n",
        "\n",
        "    select = epsilon_greedy(state, legal_moves)\n",
        "    #select = softmax(state, board.legal_moves)\n",
        "\n",
        "    return legal_moves[select], torch.tensor([[legal_moves[select]]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Training loop\n",
        "\n",
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # 合法手のみ\n",
        "    non_final_next_actions_list = []\n",
        "    for next_actions in batch.next_actions:\n",
        "        if next_actions is not None:\n",
        "            non_final_next_actions_list.append(next_actions + [next_actions[0]] * (30 - len(next_actions)))\n",
        "    non_final_next_actions = torch.tensor(non_final_next_actions_list, device=device, dtype=torch.long)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    # 合法手のみの最大値\n",
        "    target_q = target_net(non_final_next_states)\n",
        "    # 相手番の価値のため反転する\n",
        "    next_state_values[non_final_mask] = -target_q.gather(1, non_final_next_actions).max(1)[0].detach()\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = next_state_values * GAMMA + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    logging.info(f\"{episodes_done}: loss = {loss.item()}\")\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jaaeg16eMkGC"
      },
      "outputs": [],
      "source": [
        "######################################################################\n",
        "# main training loop\n",
        "\n",
        "episodes_done = 0\n",
        "for i_episode in range(12000):\n",
        "    # Initialize the environment and state\n",
        "    env.reset()\n",
        "    state = get_state(env.board)\n",
        "\n",
        "    for t in count():\n",
        "        # Select and perform an action\n",
        "        move, action = select_action(state, env.board)\n",
        "        next_board, reward, done, is_draw = env.step(move)\n",
        "\n",
        "        # todo: players\n",
        "\n",
        "        # display(SVG(env.board.to_svg(move)))\n",
        "        # print(move)\n",
        "\n",
        "\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        # print(reward)\n",
        "\n",
        "        # Observe new state\n",
        "        if not done:\n",
        "            next_state = get_state(next_board)\n",
        "            next_actions = list(next_board.legal_moves)\n",
        "        else:\n",
        "            next_state = None\n",
        "            next_actions = None\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, next_actions, reward)\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "    episodes_done += 1\n",
        "\n",
        "    if i_episode % OPTIMIZE_PER_EPISODES == OPTIMIZE_PER_EPISODES - 1:\n",
        "        # Perform several episodes of the optimization (on the target network)\n",
        "        optimize_model()\n",
        "\n",
        "        # Update the target network, copying all weights and biases in DQN\n",
        "        if i_episode // OPTIMIZE_PER_EPISODES % TARGET_UPDATE == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "model = 'epsilon_greedy_model.pt'\n",
        "print('save {}'.format(model))\n",
        "torch.save({'state_dict': target_net.state_dict(), 'optimizer': optimizer.state_dict()}, model)\n",
        "\n",
        "print('Complete')\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZMbm04o30Qp"
      },
      "outputs": [],
      "source": [
        "class RandomPlayer:\n",
        "    def go(self, board):\n",
        "        legal_moves = board.legal_moves\n",
        "        if len(legal_moves) == 0:\n",
        "            return PASS\n",
        "        else:\n",
        "            return random.choice(list(legal_moves))\n",
        "\n",
        "class GreedyPlayer:\n",
        "    def __init__(self, model_path, device, network='dqn'):\n",
        "        # if network == 'dueling':\n",
        "        #     from creversi_gym.network.cnn10_dueling import DQN\n",
        "        # else:\n",
        "        #     #from creversi_gym.network.cnn5 import DQN\n",
        "        #     from creversi_gym.network.cnn10 import DQN\n",
        "        self.device = device\n",
        "        self.model = DQN().to(device)\n",
        "        checkpoint = torch.load(model_path)\n",
        "        self.model.load_state_dict(checkpoint['state_dict'])\n",
        "        self.model.eval()\n",
        "        self.features = np.empty((1, 2, 8, 8), np.float32)\n",
        "\n",
        "    def go(self, board):\n",
        "        with torch.no_grad():\n",
        "            board.piece_planes(self.features[0])\n",
        "            state = torch.from_numpy(self.features).to(self.device)\n",
        "            q = self.model(state)\n",
        "            # 合法手に絞る\n",
        "            legal_moves = list(board.legal_moves)\n",
        "            next_actions = torch.tensor([legal_moves], device=self.device, dtype=torch.long)\n",
        "            legal_q = q.gather(1, next_actions)\n",
        "            return legal_moves[legal_q.argmax(dim=1).item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0OCa5ky4Wjk"
      },
      "outputs": [],
      "source": [
        "def vs(board, player1, player2):\n",
        "  player1name = player1.__class__.__name__\n",
        "  player2name = player2.__class__.__name__\n",
        "  print(player1name + \" vs \" + player2name)\n",
        "  print(player1name + \" Go First\")\n",
        "  while board.is_game_over() == False:\n",
        "    board.move(player1.go(board))\n",
        "    board.move(player2.go(board))\n",
        "  n_white = 64 - board.piece_num()\n",
        "  n_black = board.piece_num()\n",
        "  if n_white > n_black:\n",
        "    winner = 2\n",
        "    print(\"White Win!\")\n",
        "  elif n_black > n_white:\n",
        "    winner = 1\n",
        "    print(\"Black Win!\")\n",
        "  else:\n",
        "    winner = 0\n",
        "    print(\"Draw!\")\n",
        "  print(\"White:\",n_white)\n",
        "  print(\"Black:\",n_black)\n",
        "  return board\n",
        "\n",
        "def vs_notext(board, player1, player2):\n",
        "  while board.is_game_over() == False:\n",
        "    board.move(player1.go(board))\n",
        "    board.move(player2.go(board))\n",
        "  n_white = 64 - board.piece_num()\n",
        "  n_black = board.piece_num()\n",
        "  if n_white > n_black:\n",
        "    winner = 2\n",
        "  elif n_black > n_white:\n",
        "    winner = 1\n",
        "  else:\n",
        "    winner = 0\n",
        "  return winner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inV3P9yT34PL"
      },
      "outputs": [],
      "source": [
        "rp = RandomPlayer()\n",
        "gp = GreedyPlayer(\"/content/epsilon_greedy_model.pt\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "RdAJGJFQ5EgA",
        "outputId": "c4040eb5-0621-42ca-88d3-cf2c8b8ae4b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomPlayer vs GreedyPlayer\n",
            "RandomPlayer Go First\n",
            "White Win!\n",
            "White: 33\n",
            "Black: 31\n"
          ]
        },
        {
          "data": {
            "image/svg+xml": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"215.0\" height=\"215.0\" viewBox=\"0 0 172 172\"><defs><g id=\"black\"><circle cx=\"10\" cy=\"10\" r=\"8.5\" fill=\"black\" /></g><g id=\"white\"><circle cx=\"10\" cy=\"10\" r=\"8.5\" fill=\"white\" /></g></defs><rect fill=\"green\" height=\"161\" width=\"161\" x=\"10\" y=\"10\" /><g stroke=\"black\"><rect width=\"161\" height=\"161\" stroke-width=\"1.5\" fill=\"none\" x=\"10\" y=\"10\" /><line stroke-width=\"1.0\" x1=\"10.5\" x2=\"170.5\" y1=\"30.5\" y2=\"30.5\" /><line stroke-width=\"1.0\" x1=\"10.5\" x2=\"170.5\" y1=\"50.5\" y2=\"50.5\" /><line stroke-width=\"1.0\" x1=\"10.5\" x2=\"170.5\" y1=\"70.5\" y2=\"70.5\" /><line stroke-width=\"1.0\" x1=\"10.5\" x2=\"170.5\" y1=\"90.5\" y2=\"90.5\" /><line stroke-width=\"1.0\" x1=\"10.5\" x2=\"170.5\" y1=\"110.5\" y2=\"110.5\" /><line stroke-width=\"1.0\" x1=\"10.5\" x2=\"170.5\" y1=\"130.5\" y2=\"130.5\" /><line stroke-width=\"1.0\" x1=\"10.5\" x2=\"170.5\" y1=\"150.5\" y2=\"150.5\" /><line stroke-width=\"1.0\" x1=\"30.5\" x2=\"30.5\" y1=\"10.5\" y2=\"170.5\" /><line stroke-width=\"1.0\" x1=\"50.5\" x2=\"50.5\" y1=\"10.5\" y2=\"170.5\" /><line stroke-width=\"1.0\" x1=\"70.5\" x2=\"70.5\" y1=\"10.5\" y2=\"170.5\" /><line stroke-width=\"1.0\" x1=\"90.5\" x2=\"90.5\" y1=\"10.5\" y2=\"170.5\" /><line stroke-width=\"1.0\" x1=\"110.5\" x2=\"110.5\" y1=\"10.5\" y2=\"170.5\" /><line stroke-width=\"1.0\" x1=\"130.5\" x2=\"130.5\" y1=\"10.5\" y2=\"170.5\" /><line stroke-width=\"1.0\" x1=\"150.5\" x2=\"150.5\" y1=\"10.5\" y2=\"170.5\" /></g><g><text font-family=\"serif\" font-size=\"9.5\" text-anchor=\"middle\" x=\"20.5\" y=\"8\">a</text><text font-family=\"serif\" font-size=\"9.5\" text-anchor=\"middle\" x=\"40.5\" y=\"8\">b</text><text font-family=\"serif\" font-size=\"9.5\" text-anchor=\"middle\" x=\"60.5\" y=\"8\">c</text><text font-family=\"serif\" font-size=\"9.5\" text-anchor=\"middle\" x=\"80.5\" y=\"8\">d</text><text font-family=\"serif\" font-size=\"9.5\" text-anchor=\"middle\" x=\"100.5\" y=\"8\">e</text><text font-family=\"serif\" font-size=\"9.5\" text-anchor=\"middle\" x=\"120.5\" y=\"8\">f</text><text font-family=\"serif\" font-size=\"9.5\" text-anchor=\"middle\" x=\"140.5\" y=\"8\">g</text><text font-family=\"serif\" font-size=\"9.5\" text-anchor=\"middle\" x=\"160.5\" y=\"8\">h</text><text font-family=\"serif\" font-size=\"9.5\" x=\"2.5\" y=\"23.5\">1</text><text font-family=\"serif\" font-size=\"9.5\" x=\"2.5\" y=\"43.5\">2</text><text font-family=\"serif\" font-size=\"9.5\" x=\"2.5\" y=\"63.5\">3</text><text font-family=\"serif\" font-size=\"9.5\" x=\"2.5\" y=\"83.5\">4</text><text font-family=\"serif\" font-size=\"9.5\" x=\"2.5\" y=\"103.5\">5</text><text font-family=\"serif\" font-size=\"9.5\" x=\"2.5\" y=\"123.5\">6</text><text font-family=\"serif\" font-size=\"9.5\" x=\"2.5\" y=\"143.5\">7</text><text font-family=\"serif\" font-size=\"9.5\" x=\"2.5\" y=\"163.5\">8</text></g><use xlink:href=\"#white\" x=\"10.5\" y=\"10.5\" /><use xlink:href=\"#white\" x=\"30.5\" y=\"10.5\" /><use xlink:href=\"#white\" x=\"50.5\" y=\"10.5\" /><use xlink:href=\"#white\" x=\"70.5\" y=\"10.5\" /><use xlink:href=\"#white\" x=\"90.5\" y=\"10.5\" /><use xlink:href=\"#white\" x=\"110.5\" y=\"10.5\" /><use xlink:href=\"#white\" x=\"130.5\" y=\"10.5\" /><use xlink:href=\"#black\" x=\"150.5\" y=\"10.5\" /><use xlink:href=\"#white\" x=\"10.5\" y=\"30.5\" /><use xlink:href=\"#black\" x=\"30.5\" y=\"30.5\" /><use xlink:href=\"#white\" x=\"50.5\" y=\"30.5\" /><use xlink:href=\"#black\" x=\"70.5\" y=\"30.5\" /><use xlink:href=\"#black\" x=\"90.5\" y=\"30.5\" /><use xlink:href=\"#black\" x=\"110.5\" y=\"30.5\" /><use xlink:href=\"#black\" x=\"130.5\" y=\"30.5\" /><use xlink:href=\"#black\" x=\"150.5\" y=\"30.5\" /><use xlink:href=\"#white\" x=\"10.5\" y=\"50.5\" /><use xlink:href=\"#white\" x=\"30.5\" y=\"50.5\" /><use xlink:href=\"#black\" x=\"50.5\" y=\"50.5\" /><use xlink:href=\"#white\" x=\"70.5\" y=\"50.5\" /><use xlink:href=\"#black\" x=\"90.5\" y=\"50.5\" /><use xlink:href=\"#black\" x=\"110.5\" y=\"50.5\" /><use xlink:href=\"#black\" x=\"130.5\" y=\"50.5\" /><use xlink:href=\"#black\" x=\"150.5\" y=\"50.5\" /><use xlink:href=\"#white\" x=\"10.5\" y=\"70.5\" /><use xlink:href=\"#white\" x=\"30.5\" y=\"70.5\" /><use xlink:href=\"#white\" x=\"50.5\" y=\"70.5\" /><use xlink:href=\"#black\" x=\"70.5\" y=\"70.5\" /><use xlink:href=\"#black\" x=\"90.5\" y=\"70.5\" /><use xlink:href=\"#white\" x=\"110.5\" y=\"70.5\" /><use xlink:href=\"#white\" x=\"130.5\" y=\"70.5\" /><use xlink:href=\"#black\" x=\"150.5\" y=\"70.5\" /><use xlink:href=\"#white\" x=\"10.5\" y=\"90.5\" /><use xlink:href=\"#white\" x=\"30.5\" y=\"90.5\" /><use xlink:href=\"#black\" x=\"50.5\" y=\"90.5\" /><use xlink:href=\"#black\" x=\"70.5\" y=\"90.5\" /><use xlink:href=\"#white\" x=\"90.5\" y=\"90.5\" /><use xlink:href=\"#black\" x=\"110.5\" y=\"90.5\" /><use xlink:href=\"#white\" x=\"130.5\" y=\"90.5\" /><use xlink:href=\"#black\" x=\"150.5\" y=\"90.5\" /><use xlink:href=\"#white\" x=\"10.5\" y=\"110.5\" /><use xlink:href=\"#white\" x=\"30.5\" y=\"110.5\" /><use xlink:href=\"#white\" x=\"50.5\" y=\"110.5\" /><use xlink:href=\"#white\" x=\"70.5\" y=\"110.5\" /><use xlink:href=\"#white\" x=\"90.5\" y=\"110.5\" /><use xlink:href=\"#white\" x=\"110.5\" y=\"110.5\" /><use xlink:href=\"#white\" x=\"130.5\" y=\"110.5\" /><use xlink:href=\"#black\" x=\"150.5\" y=\"110.5\" /><use xlink:href=\"#white\" x=\"10.5\" y=\"130.5\" /><use xlink:href=\"#black\" x=\"30.5\" y=\"130.5\" /><use xlink:href=\"#white\" x=\"50.5\" y=\"130.5\" /><use xlink:href=\"#white\" x=\"70.5\" y=\"130.5\" /><use xlink:href=\"#white\" x=\"90.5\" y=\"130.5\" /><use xlink:href=\"#black\" x=\"110.5\" y=\"130.5\" /><use xlink:href=\"#black\" x=\"130.5\" y=\"130.5\" /><use xlink:href=\"#black\" x=\"150.5\" y=\"130.5\" /><use xlink:href=\"#black\" x=\"10.5\" y=\"150.5\" /><use xlink:href=\"#black\" x=\"30.5\" y=\"150.5\" /><use xlink:href=\"#black\" x=\"50.5\" y=\"150.5\" /><use xlink:href=\"#black\" x=\"70.5\" y=\"150.5\" /><use xlink:href=\"#black\" x=\"90.5\" y=\"150.5\" /><use xlink:href=\"#black\" x=\"110.5\" y=\"150.5\" /><use xlink:href=\"#black\" x=\"130.5\" y=\"150.5\" /><use xlink:href=\"#white\" x=\"150.5\" y=\"150.5\" /></svg>"
            ],
            "text/plain": [
              " |abcdefgh\n",
              "-+--------\n",
              "1|ooooooox\n",
              "2|oxoxxxxx\n",
              "3|ooxoxxxx\n",
              "4|oooxxoox\n",
              "5|ooxxoxox\n",
              "6|ooooooox\n",
              "7|oxoooxxx\n",
              "8|xxxxxxxo"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newboard = creversi.Board()\n",
        "vs(newboard, rp, gp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBowWmRR6gPp"
      },
      "outputs": [],
      "source": [
        "rpwin = 0\n",
        "gpwin = 0\n",
        "draw = 0\n",
        "for i in range(500):\n",
        "  board = creversi.Board()\n",
        "  result = vs_notext(board, rp, gp)\n",
        "  if result == 1:\n",
        "    rpwin += 1\n",
        "  elif result == 2:\n",
        "    gpwin += 1\n",
        "  else:\n",
        "    draw += 1\n",
        "\n",
        "  board = creversi.Board()\n",
        "  result = vs_notext(board, gp, rp)\n",
        "  if result == 1:\n",
        "    gpwin += 1\n",
        "  elif result == 2:\n",
        "    rpwin += 1\n",
        "  else:\n",
        "    draw += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oleFxBZ74fE",
        "outputId": "28fe39a3-c954-4ed6-ddd2-acb94dba0866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomPlayer vs GreedyPlayer\n",
            "RandomPlayer Win: 407\n",
            "GreedyPlayer Win: 556\n",
            "Draw: 37\n",
            "RandomPlayer Win Rate: 0.407\n",
            "GreedyPlayer Win Rate: 0.556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "print(\"RandomPlayer vs GreedyPlayer\")\n",
        "print(\"RandomPlayer Win:\", rpwin)\n",
        "print(\"GreedyPlayer Win:\", gpwin)\n",
        "print(\"Draw:\", draw)\n",
        "print(\"RandomPlayer Win Rate:\", rpwin/(rpwin+gpwin+draw))\n",
        "print(\"GreedyPlayer Win Rate:\", gpwin/(rpwin+gpwin+draw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj3D9R1191jV"
      },
      "outputs": [],
      "source": [
        "rp1 = RandomPlayer()\n",
        "rp2 = RandomPlayer()\n",
        "\n",
        "rp1win = 0\n",
        "rp2win = 0\n",
        "draw = 0\n",
        "for i in range(500):\n",
        "  board = creversi.Board()\n",
        "  result = vs_notext(board, rp1, rp2)\n",
        "  if result == 1:\n",
        "    rp1win += 1\n",
        "  elif result == 2:\n",
        "    rp2win += 1\n",
        "  else:\n",
        "    draw += 1\n",
        "\n",
        "  board = creversi.Board()\n",
        "  result = vs_notext(board, rp2, rp1)\n",
        "  if result == 1:\n",
        "    rp2win += 1\n",
        "  elif result == 2:\n",
        "    rp1win += 1\n",
        "  else:\n",
        "    draw += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0LYsphq-XAY",
        "outputId": "eb534023-1cb2-4c1a-dc0f-54ec289d7cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomPlayer vs RandomPlayer\n",
            "RandomPlayer1 Win: 492\n",
            "RandomPlayer2 Win: 474\n",
            "Draw: 34\n",
            "RandomPlayer1 Win Rate: 0.492\n",
            "RandomPlayer2 Win Rate: 0.474\n"
          ]
        }
      ],
      "source": [
        "print(\"RandomPlayer vs RandomPlayer\")\n",
        "print(\"RandomPlayer1 Win:\", rp1win)\n",
        "print(\"RandomPlayer2 Win:\", rp2win)\n",
        "print(\"Draw:\", draw)\n",
        "print(\"RandomPlayer1 Win Rate:\", rp1win/(rp1win+rp2win+draw))\n",
        "print(\"RandomPlayer2 Win Rate:\", rp2win/(rp1win+rp2win+draw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wqxdeeX-Aq2"
      },
      "outputs": [],
      "source": [
        "gp1 = GreedyPlayer(\"/content/epsilon_greedy_model.pt\", device)\n",
        "gp2 = GreedyPlayer(\"/content/epsilon_greedy_model.pt\", device)\n",
        "\n",
        "gp1win = 0\n",
        "gp2win = 0\n",
        "draw = 0\n",
        "for i in range(500):\n",
        "  board = creversi.Board()\n",
        "  result = vs_notext(board, gp1, gp2)\n",
        "  if result == 1:\n",
        "    gp1win += 1\n",
        "  elif result == 2:\n",
        "    gp2win += 1\n",
        "  else:\n",
        "    draw += 1\n",
        "\n",
        "  board = creversi.Board()\n",
        "  result = vs_notext(board, gp2, gp1)\n",
        "  if result == 1:\n",
        "    gp2win += 1\n",
        "  elif result == 2:\n",
        "    gp1win += 1\n",
        "  else:\n",
        "    draw += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGPeAUxC-bZY",
        "outputId": "3ed60e90-652a-45f9-8ca2-ca4fb8a47150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GreedyPlayer vs GreedyPlayer\n",
            "GreedyPlayer1 Win: 500\n",
            "GreedyPlayer2 Win: 500\n",
            "Draw: 0\n",
            "GreedyPlayer1 Win Rate: 0.5\n",
            "GreedyPlayer2 Win Rate: 0.5\n"
          ]
        }
      ],
      "source": [
        "print(\"GreedyPlayer vs GreedyPlayer\")\n",
        "print(\"GreedyPlayer1 Win:\", gp1win)\n",
        "print(\"GreedyPlayer2 Win:\", gp2win)\n",
        "print(\"Draw:\", draw)\n",
        "print(\"GreedyPlayer1 Win Rate:\", gp1win/(gp1win+gp2win+draw))\n",
        "print(\"GreedyPlayer2 Win Rate:\", gp2win/(gp1win+gp2win+draw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg3aVla_LIrk"
      },
      "outputs": [],
      "source": [
        "import creversi\n",
        "import random\n",
        "\n",
        "class QLearning:\n",
        "    def __init__(self):\n",
        "        self.q_table = {}\n",
        "\n",
        "    def get_q_value(self, state, action):\n",
        "        return self.q_table.get((state, action), 0.0)\n",
        "\n",
        "    def update_q_value(self, state, action, value):\n",
        "        self.q_table[(state, action)] = value\n",
        "\n",
        "class QAgent:\n",
        "    def __init__(self, epsilon=0.1, alpha=0.1, gamma=0.9):\n",
        "        self.epsilon = epsilon\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.q_learning = QLearning()\n",
        "\n",
        "    def choose_action(self, state, legal_moves):\n",
        "        if random.uniform(0, 1) < self.epsilon:\n",
        "            return random.choice(legal_moves)\n",
        "        else:\n",
        "            q_values = [self.q_learning.get_q_value(state, action) for action in legal_moves]\n",
        "            max_q_value = max(q_values)\n",
        "            best_actions = [action for action, value in zip(legal_moves, q_values) if value == max_q_value]\n",
        "            return random.choice(best_actions)\n",
        "\n",
        "    def train(self, state, action, reward, next_state, legal_moves):\n",
        "        current_q_value = self.q_learning.get_q_value(state, action)\n",
        "        max_next_q_value = max([self.q_learning.get_q_value(next_state, next_action) for next_action in legal_moves])\n",
        "        new_q_value = (1 - self.alpha) * current_q_value + self.alpha * (reward + self.gamma * max_next_q_value)\n",
        "        self.q_learning.update_q_value(state, action, new_q_value)\n",
        "\n",
        "    def reset_q_table(self):\n",
        "        self.q_learning = QLearning()\n",
        "\n",
        "class RandomAgent:\n",
        "    def choose_action(self, state, legal_moves):\n",
        "        return random.choice(legal_moves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrMGrwb-LR1f"
      },
      "outputs": [],
      "source": [
        "def print_board(board):\n",
        "    print(str(board))\n",
        "\n",
        "def play_game(q_agent, opponent_agent, board, first = True):\n",
        "    if first:\n",
        "      current_agent = q_agent\n",
        "    else:\n",
        "      current_agent = opponent_agent\n",
        "\n",
        "    while not board.is_game_over():\n",
        "        state = str(board)\n",
        "        legal_moves = [creversi.move_to_str(move) for move in board.legal_moves]\n",
        "\n",
        "        # print_board(board)\n",
        "\n",
        "        if isinstance(current_agent, QAgent):\n",
        "            action = current_agent.choose_action(state, legal_moves)\n",
        "            board.move_from_str(action)\n",
        "        else:\n",
        "            action = opponent_agent.go(board)\n",
        "            board.move(action)\n",
        "\n",
        "        # board.move_from_str(action)\n",
        "        current_agent = opponent_agent if current_agent == q_agent else q_agent\n",
        "\n",
        "    # print(\"end with q_agent\" if current_agent == q_agent else \"end with opponent_agent\")\n",
        "    if first:\n",
        "      firstname = \"q_agent\"\n",
        "      secondname = \"opponent_agent\"\n",
        "    else:\n",
        "      firstname = \"opponent_agent\"\n",
        "      secondname = \"q_agent\"\n",
        "    if current_agent == opponent_agent:\n",
        "      n_black = 64 - board.piece_num()\n",
        "      n_white = board.piece_num()\n",
        "    else:\n",
        "      n_white = 64 - board.piece_num()\n",
        "      n_black = board.piece_num()\n",
        "    if n_white > n_black:\n",
        "      if first:\n",
        "        winner = 2\n",
        "      else:\n",
        "        winner = 1\n",
        "      print(secondname + \" white win\", n_white)\n",
        "    elif n_black > n_white:\n",
        "      if first:\n",
        "        winner = 1\n",
        "      else:\n",
        "        winner = 2\n",
        "      print(firstname + \" black win\", n_black)\n",
        "    else:\n",
        "      winner = 0\n",
        "      print(\"draw\")\n",
        "\n",
        "    return winner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJBNvvihLWAo"
      },
      "outputs": [],
      "source": [
        "q_agent = QAgent()\n",
        "opponent_agent = GreedyPlayer(\"/content/epsilon_greedy_model.pt\", device)\n",
        "board = creversi.Board()\n",
        "\n",
        "opponent_agentcount = 0\n",
        "q_agentcount = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKr_9DdDRq6g",
        "outputId": "6ad39379-64dc-4fe9-c71b-69c7399045a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opponent_agent white win 49\n",
            "q_agent white win 47\n",
            "opponent_agent white win 40\n",
            "opponent_agent black win 38\n",
            "q_agent black win 55\n",
            "q_agent white win 37\n",
            "opponent_agent white win 39\n",
            "q_agent white win 46\n",
            "q_agent black win 35\n",
            "q_agent white win 40\n",
            "opponent_agent white win 49\n",
            "q_agent white win 41\n",
            "opponent_agent white win 39\n",
            "draw\n",
            "opponent_agent white win 51\n",
            "q_agent white win 51\n",
            "opponent_agent white win 43\n",
            "opponent_agent black win 37\n",
            "opponent_agent white win 35\n",
            "opponent_agent black win 36\n",
            "q_agent black win 51\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 47\n",
            "q_agent white win 54\n",
            "q_agent black win 33\n",
            "q_agent white win 39\n",
            "opponent_agent white win 47\n",
            "opponent_agent black win 40\n",
            "opponent_agent white win 46\n",
            "q_agent white win 36\n",
            "draw\n",
            "q_agent white win 46\n",
            "opponent_agent white win 39\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 34\n",
            "q_agent white win 35\n",
            "opponent_agent white win 33\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 39\n",
            "opponent_agent black win 55\n",
            "q_agent black win 36\n",
            "q_agent white win 35\n",
            "opponent_agent white win 35\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 42\n",
            "q_agent white win 38\n",
            "q_agent black win 33\n",
            "opponent_agent black win 37\n",
            "opponent_agent white win 44\n",
            "opponent_agent black win 33\n",
            "q_agent black win 42\n",
            "opponent_agent black win 34\n",
            "opponent_agent white win 40\n",
            "opponent_agent black win 40\n",
            "opponent_agent white win 41\n",
            "q_agent white win 43\n",
            "opponent_agent white win 35\n",
            "opponent_agent black win 39\n",
            "opponent_agent white win 36\n",
            "opponent_agent black win 34\n",
            "q_agent black win 38\n",
            "q_agent white win 40\n",
            "opponent_agent white win 36\n",
            "q_agent white win 39\n",
            "q_agent black win 33\n",
            "opponent_agent black win 47\n",
            "opponent_agent white win 36\n",
            "q_agent white win 36\n",
            "q_agent black win 34\n",
            "q_agent white win 36\n",
            "draw\n",
            "opponent_agent black win 39\n",
            "opponent_agent white win 37\n",
            "q_agent white win 41\n",
            "opponent_agent white win 44\n",
            "q_agent white win 35\n",
            "opponent_agent white win 37\n",
            "opponent_agent black win 35\n",
            "q_agent black win 45\n",
            "q_agent white win 41\n",
            "opponent_agent white win 36\n",
            "opponent_agent black win 36\n",
            "q_agent black win 34\n",
            "q_agent white win 40\n",
            "opponent_agent white win 43\n",
            "opponent_agent black win 34\n",
            "q_agent black win 36\n",
            "opponent_agent black win 40\n",
            "opponent_agent white win 37\n",
            "q_agent white win 36\n",
            "opponent_agent white win 42\n",
            "q_agent white win 49\n",
            "opponent_agent white win 43\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 38\n",
            "opponent_agent black win 43\n",
            "opponent_agent white win 36\n",
            "q_agent white win 40\n",
            "q_agent black win 42\n",
            "q_agent white win 33\n",
            "q_agent black win 49\n",
            "opponent_agent black win 38\n",
            "q_agent black win 36\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 41\n",
            "opponent_agent black win 37\n",
            "q_agent black win 40\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 33\n",
            "opponent_agent black win 46\n",
            "q_agent black win 35\n",
            "opponent_agent black win 41\n",
            "q_agent black win 41\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 34\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 42\n",
            "q_agent white win 34\n",
            "opponent_agent white win 40\n",
            "q_agent white win 49\n",
            "opponent_agent white win 41\n",
            "q_agent white win 43\n",
            "opponent_agent white win 41\n",
            "opponent_agent black win 36\n",
            "q_agent black win 49\n",
            "q_agent white win 46\n",
            "draw\n",
            "q_agent white win 39\n",
            "q_agent black win 38\n",
            "opponent_agent black win 44\n",
            "draw\n",
            "opponent_agent black win 35\n",
            "q_agent black win 36\n",
            "q_agent white win 40\n",
            "opponent_agent white win 36\n",
            "q_agent white win 39\n",
            "opponent_agent white win 41\n",
            "q_agent white win 41\n",
            "opponent_agent white win 44\n",
            "q_agent white win 37\n",
            "opponent_agent white win 43\n",
            "opponent_agent black win 42\n",
            "draw\n",
            "q_agent white win 39\n",
            "draw\n",
            "q_agent white win 40\n",
            "q_agent black win 38\n",
            "q_agent white win 35\n",
            "draw\n",
            "q_agent white win 41\n",
            "opponent_agent white win 38\n",
            "opponent_agent black win 42\n",
            "opponent_agent white win 43\n",
            "q_agent white win 33\n",
            "opponent_agent white win 37\n",
            "q_agent white win 38\n",
            "opponent_agent white win 43\n",
            "opponent_agent black win 39\n",
            "opponent_agent white win 37\n",
            "q_agent white win 33\n",
            "q_agent black win 35\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 44\n",
            "q_agent white win 41\n",
            "opponent_agent white win 33\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 43\n",
            "q_agent white win 44\n",
            "q_agent black win 42\n",
            "q_agent white win 42\n",
            "opponent_agent white win 49\n",
            "q_agent white win 44\n",
            "q_agent black win 34\n",
            "q_agent white win 45\n",
            "q_agent black win 36\n",
            "q_agent white win 38\n",
            "opponent_agent white win 33\n",
            "q_agent white win 49\n",
            "opponent_agent white win 47\n",
            "opponent_agent black win 37\n",
            "opponent_agent white win 38\n",
            "q_agent white win 36\n",
            "opponent_agent white win 40\n",
            "opponent_agent black win 40\n",
            "q_agent black win 42\n",
            "opponent_agent black win 35\n",
            "q_agent black win 34\n",
            "q_agent white win 33\n",
            "q_agent black win 46\n",
            "opponent_agent black win 38\n",
            "q_agent black win 40\n",
            "opponent_agent black win 43\n",
            "opponent_agent white win 36\n",
            "opponent_agent black win 37\n",
            "q_agent black win 35\n",
            "q_agent white win 39\n",
            "opponent_agent white win 50\n",
            "q_agent white win 44\n",
            "q_agent black win 41\n",
            "q_agent white win 42\n",
            "opponent_agent white win 36\n",
            "q_agent white win 36\n",
            "opponent_agent white win 55\n",
            "q_agent white win 36\n",
            "q_agent black win 33\n",
            "q_agent white win 44\n",
            "q_agent black win 36\n",
            "q_agent white win 34\n",
            "q_agent black win 44\n",
            "q_agent white win 39\n",
            "opponent_agent white win 37\n",
            "opponent_agent black win 46\n",
            "q_agent black win 34\n",
            "q_agent white win 37\n",
            "q_agent black win 36\n",
            "q_agent white win 42\n",
            "q_agent black win 35\n",
            "q_agent white win 44\n",
            "q_agent black win 37\n",
            "opponent_agent black win 40\n",
            "opponent_agent white win 40\n",
            "opponent_agent black win 42\n",
            "opponent_agent white win 35\n",
            "opponent_agent black win 44\n",
            "opponent_agent white win 35\n",
            "opponent_agent black win 40\n",
            "opponent_agent white win 46\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 44\n",
            "q_agent white win 47\n",
            "q_agent black win 34\n",
            "q_agent white win 33\n",
            "q_agent black win 41\n",
            "q_agent white win 53\n",
            "opponent_agent white win 43\n",
            "q_agent white win 35\n",
            "opponent_agent white win 41\n",
            "opponent_agent black win 37\n",
            "opponent_agent white win 46\n",
            "opponent_agent black win 46\n",
            "draw\n",
            "opponent_agent black win 35\n",
            "q_agent black win 43\n",
            "draw\n",
            "opponent_agent white win 33\n",
            "q_agent white win 40\n",
            "opponent_agent white win 48\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 43\n",
            "q_agent white win 43\n",
            "q_agent black win 47\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 52\n",
            "q_agent white win 39\n",
            "draw\n",
            "q_agent white win 39\n",
            "q_agent black win 45\n",
            "opponent_agent black win 39\n",
            "opponent_agent white win 46\n",
            "opponent_agent black win 47\n",
            "opponent_agent white win 40\n",
            "draw\n",
            "opponent_agent white win 45\n",
            "opponent_agent black win 44\n",
            "q_agent black win 41\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 35\n",
            "q_agent white win 34\n",
            "q_agent black win 37\n",
            "draw\n",
            "opponent_agent white win 33\n",
            "q_agent white win 43\n",
            "opponent_agent white win 38\n",
            "q_agent white win 33\n",
            "q_agent black win 39\n",
            "opponent_agent black win 37\n",
            "q_agent black win 39\n",
            "q_agent white win 35\n",
            "opponent_agent white win 36\n",
            "q_agent white win 36\n",
            "opponent_agent white win 40\n",
            "opponent_agent black win 37\n",
            "q_agent black win 40\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 47\n",
            "q_agent white win 53\n",
            "opponent_agent white win 39\n",
            "q_agent white win 34\n",
            "opponent_agent white win 38\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 37\n",
            "draw\n",
            "q_agent black win 40\n",
            "q_agent white win 38\n",
            "q_agent black win 33\n",
            "opponent_agent black win 36\n",
            "q_agent black win 36\n",
            "draw\n",
            "opponent_agent white win 47\n",
            "opponent_agent black win 47\n",
            "q_agent black win 35\n",
            "opponent_agent black win 41\n",
            "q_agent black win 42\n",
            "opponent_agent black win 52\n",
            "q_agent black win 36\n",
            "q_agent white win 33\n",
            "q_agent black win 38\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 35\n",
            "q_agent white win 40\n",
            "q_agent black win 36\n",
            "q_agent white win 44\n",
            "opponent_agent white win 47\n",
            "q_agent white win 40\n",
            "q_agent black win 43\n",
            "opponent_agent black win 51\n",
            "q_agent black win 43\n",
            "q_agent white win 34\n",
            "opponent_agent white win 50\n",
            "opponent_agent black win 34\n",
            "q_agent black win 41\n",
            "q_agent white win 47\n",
            "q_agent black win 35\n",
            "opponent_agent black win 42\n",
            "opponent_agent white win 39\n",
            "q_agent white win 41\n",
            "opponent_agent white win 34\n",
            "draw\n",
            "opponent_agent white win 41\n",
            "opponent_agent black win 37\n",
            "q_agent black win 49\n",
            "opponent_agent black win 35\n",
            "q_agent black win 41\n",
            "opponent_agent black win 34\n",
            "q_agent black win 36\n",
            "opponent_agent black win 40\n",
            "q_agent black win 39\n",
            "draw\n",
            "opponent_agent white win 40\n",
            "opponent_agent black win 42\n",
            "q_agent black win 40\n",
            "q_agent white win 38\n",
            "opponent_agent white win 35\n",
            "opponent_agent black win 35\n",
            "q_agent black win 49\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 50\n",
            "q_agent white win 38\n",
            "q_agent black win 35\n",
            "q_agent white win 33\n",
            "opponent_agent white win 36\n",
            "q_agent white win 39\n",
            "opponent_agent white win 38\n",
            "opponent_agent black win 34\n",
            "opponent_agent white win 44\n",
            "q_agent white win 37\n",
            "opponent_agent white win 43\n",
            "opponent_agent black win 34\n",
            "q_agent black win 41\n",
            "opponent_agent black win 38\n",
            "q_agent black win 34\n",
            "q_agent white win 36\n",
            "q_agent black win 33\n",
            "q_agent white win 41\n",
            "opponent_agent white win 42\n",
            "q_agent white win 43\n",
            "opponent_agent white win 58\n",
            "q_agent white win 40\n",
            "opponent_agent white win 47\n",
            "opponent_agent black win 34\n",
            "opponent_agent white win 37\n",
            "q_agent white win 37\n",
            "opponent_agent white win 36\n",
            "opponent_agent black win 42\n",
            "opponent_agent white win 49\n",
            "q_agent white win 37\n",
            "opponent_agent white win 33\n",
            "draw\n",
            "opponent_agent white win 49\n",
            "opponent_agent black win 49\n",
            "q_agent black win 39\n",
            "q_agent white win 38\n",
            "q_agent black win 37\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 41\n",
            "opponent_agent black win 33\n",
            "q_agent black win 33\n",
            "draw\n",
            "q_agent black win 38\n",
            "q_agent white win 36\n",
            "q_agent black win 40\n",
            "q_agent white win 33\n",
            "q_agent black win 36\n",
            "q_agent white win 42\n",
            "q_agent black win 35\n",
            "opponent_agent black win 42\n",
            "opponent_agent white win 45\n",
            "opponent_agent black win 33\n",
            "q_agent black win 44\n",
            "q_agent white win 44\n",
            "opponent_agent white win 34\n",
            "opponent_agent black win 39\n",
            "opponent_agent white win 43\n",
            "q_agent white win 46\n",
            "q_agent black win 35\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 37\n",
            "q_agent white win 36\n",
            "opponent_agent white win 42\n",
            "q_agent white win 36\n",
            "opponent_agent white win 38\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 37\n",
            "q_agent white win 38\n",
            "opponent_agent white win 35\n",
            "opponent_agent black win 41\n",
            "q_agent black win 35\n",
            "q_agent white win 42\n",
            "draw\n",
            "opponent_agent black win 41\n",
            "q_agent black win 33\n",
            "opponent_agent black win 46\n",
            "q_agent black win 37\n",
            "q_agent white win 35\n",
            "opponent_agent white win 37\n",
            "q_agent white win 35\n",
            "q_agent black win 43\n",
            "q_agent white win 41\n",
            "q_agent black win 35\n",
            "q_agent white win 33\n",
            "opponent_agent white win 38\n",
            "q_agent white win 33\n",
            "opponent_agent white win 48\n",
            "q_agent white win 35\n",
            "opponent_agent white win 51\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 37\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 48\n",
            "opponent_agent black win 48\n",
            "q_agent black win 37\n",
            "q_agent white win 47\n",
            "q_agent black win 35\n",
            "q_agent white win 45\n",
            "q_agent black win 38\n",
            "opponent_agent black win 45\n",
            "q_agent black win 39\n",
            "q_agent white win 37\n",
            "opponent_agent white win 39\n",
            "q_agent white win 45\n",
            "opponent_agent white win 38\n",
            "opponent_agent black win 47\n",
            "opponent_agent white win 40\n",
            "q_agent white win 42\n",
            "q_agent black win 36\n",
            "q_agent white win 35\n",
            "opponent_agent white win 35\n",
            "q_agent white win 48\n",
            "opponent_agent white win 46\n",
            "q_agent white win 40\n",
            "q_agent black win 33\n",
            "opponent_agent black win 37\n",
            "q_agent black win 34\n",
            "q_agent white win 45\n",
            "opponent_agent white win 36\n",
            "q_agent white win 41\n",
            "opponent_agent white win 40\n",
            "q_agent white win 39\n",
            "opponent_agent white win 33\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 44\n",
            "q_agent white win 36\n",
            "opponent_agent white win 41\n",
            "q_agent white win 38\n",
            "opponent_agent white win 45\n",
            "q_agent white win 37\n",
            "opponent_agent white win 46\n",
            "q_agent white win 36\n",
            "opponent_agent white win 36\n",
            "q_agent white win 33\n",
            "q_agent black win 43\n",
            "q_agent white win 37\n",
            "opponent_agent white win 34\n",
            "opponent_agent black win 40\n",
            "opponent_agent white win 35\n",
            "q_agent white win 36\n",
            "opponent_agent white win 35\n",
            "draw\n",
            "q_agent black win 36\n",
            "q_agent white win 49\n",
            "opponent_agent white win 43\n",
            "opponent_agent black win 35\n",
            "q_agent black win 47\n",
            "q_agent white win 35\n",
            "opponent_agent white win 41\n",
            "q_agent white win 40\n",
            "q_agent black win 38\n",
            "q_agent white win 40\n",
            "opponent_agent white win 34\n",
            "opponent_agent black win 40\n",
            "opponent_agent white win 48\n",
            "opponent_agent black win 43\n",
            "opponent_agent white win 42\n",
            "q_agent white win 40\n",
            "opponent_agent white win 39\n",
            "q_agent white win 42\n",
            "q_agent black win 35\n",
            "q_agent white win 52\n",
            "opponent_agent white win 43\n",
            "q_agent white win 40\n",
            "opponent_agent white win 39\n",
            "q_agent white win 43\n",
            "opponent_agent white win 37\n",
            "q_agent white win 43\n",
            "q_agent black win 44\n",
            "q_agent white win 35\n",
            "opponent_agent white win 47\n",
            "q_agent white win 34\n",
            "q_agent black win 36\n",
            "q_agent white win 44\n",
            "opponent_agent white win 39\n",
            "draw\n",
            "opponent_agent white win 35\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 45\n",
            "opponent_agent black win 42\n",
            "opponent_agent white win 35\n",
            "q_agent white win 40\n",
            "q_agent black win 35\n",
            "q_agent white win 34\n",
            "q_agent black win 45\n",
            "opponent_agent black win 34\n",
            "q_agent black win 35\n",
            "q_agent white win 37\n",
            "q_agent black win 41\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 41\n",
            "q_agent white win 45\n",
            "q_agent black win 44\n",
            "q_agent white win 33\n",
            "opponent_agent white win 44\n",
            "opponent_agent black win 41\n",
            "q_agent black win 36\n",
            "opponent_agent black win 34\n",
            "q_agent black win 33\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 34\n",
            "opponent_agent black win 34\n",
            "opponent_agent white win 44\n",
            "q_agent white win 47\n",
            "q_agent black win 42\n",
            "opponent_agent black win 34\n",
            "q_agent black win 34\n",
            "opponent_agent black win 35\n",
            "q_agent black win 36\n",
            "opponent_agent black win 44\n",
            "opponent_agent white win 34\n",
            "q_agent white win 34\n",
            "opponent_agent white win 40\n",
            "q_agent white win 48\n",
            "opponent_agent white win 42\n",
            "q_agent white win 37\n",
            "opponent_agent white win 38\n",
            "q_agent white win 56\n",
            "opponent_agent white win 41\n",
            "opponent_agent black win 41\n",
            "opponent_agent white win 48\n",
            "q_agent white win 37\n",
            "opponent_agent white win 34\n",
            "q_agent white win 36\n",
            "opponent_agent white win 33\n",
            "q_agent white win 41\n",
            "opponent_agent white win 37\n",
            "q_agent white win 35\n",
            "opponent_agent white win 38\n",
            "q_agent white win 42\n",
            "q_agent black win 36\n",
            "q_agent white win 37\n",
            "q_agent black win 33\n",
            "draw\n",
            "q_agent black win 40\n",
            "q_agent white win 34\n",
            "q_agent black win 45\n",
            "opponent_agent black win 40\n",
            "q_agent black win 43\n",
            "q_agent white win 34\n",
            "opponent_agent white win 40\n",
            "opponent_agent black win 46\n",
            "q_agent black win 42\n",
            "q_agent white win 37\n",
            "q_agent black win 33\n",
            "opponent_agent black win 49\n",
            "q_agent black win 34\n",
            "opponent_agent black win 41\n",
            "opponent_agent white win 36\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 37\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 38\n",
            "opponent_agent black win 39\n",
            "opponent_agent white win 44\n",
            "q_agent white win 41\n",
            "opponent_agent white win 34\n",
            "q_agent white win 41\n",
            "opponent_agent white win 39\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 45\n",
            "q_agent white win 36\n",
            "opponent_agent white win 37\n",
            "opponent_agent black win 39\n",
            "q_agent black win 40\n",
            "q_agent white win 42\n",
            "draw\n",
            "q_agent white win 34\n",
            "opponent_agent white win 53\n",
            "q_agent white win 49\n",
            "opponent_agent white win 40\n",
            "opponent_agent black win 39\n",
            "q_agent black win 40\n",
            "opponent_agent black win 34\n",
            "opponent_agent white win 45\n",
            "opponent_agent black win 45\n",
            "q_agent black win 36\n",
            "q_agent white win 39\n",
            "q_agent black win 35\n",
            "q_agent white win 36\n",
            "opponent_agent white win 41\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 43\n",
            "q_agent white win 42\n",
            "opponent_agent white win 51\n",
            "opponent_agent black win 44\n",
            "opponent_agent white win 43\n",
            "opponent_agent black win 34\n",
            "q_agent black win 39\n",
            "draw\n",
            "opponent_agent white win 43\n",
            "opponent_agent black win 45\n",
            "q_agent black win 37\n",
            "q_agent white win 50\n",
            "opponent_agent white win 41\n",
            "opponent_agent black win 37\n",
            "opponent_agent white win 34\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 37\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 46\n",
            "q_agent white win 43\n",
            "q_agent black win 40\n",
            "opponent_agent black win 42\n",
            "opponent_agent white win 42\n",
            "opponent_agent black win 37\n",
            "q_agent black win 35\n",
            "q_agent white win 37\n",
            "opponent_agent white win 33\n",
            "q_agent white win 42\n",
            "opponent_agent white win 41\n",
            "q_agent white win 40\n",
            "opponent_agent white win 44\n",
            "opponent_agent black win 37\n",
            "q_agent black win 36\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 34\n",
            "q_agent white win 46\n",
            "q_agent black win 35\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 33\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 36\n",
            "q_agent white win 48\n",
            "opponent_agent white win 36\n",
            "opponent_agent black win 42\n",
            "q_agent black win 38\n",
            "opponent_agent black win 51\n",
            "opponent_agent white win 37\n",
            "q_agent white win 38\n",
            "opponent_agent white win 42\n",
            "opponent_agent black win 40\n",
            "q_agent black win 35\n",
            "opponent_agent black win 41\n",
            "opponent_agent white win 36\n",
            "q_agent white win 36\n",
            "opponent_agent white win 54\n",
            "q_agent white win 34\n",
            "opponent_agent white win 33\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 43\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 34\n",
            "opponent_agent black win 42\n",
            "opponent_agent white win 44\n",
            "q_agent white win 36\n",
            "opponent_agent white win 47\n",
            "opponent_agent black win 39\n",
            "opponent_agent white win 33\n",
            "opponent_agent black win 44\n",
            "opponent_agent white win 37\n",
            "opponent_agent black win 38\n",
            "q_agent black win 45\n",
            "opponent_agent black win 40\n",
            "q_agent black win 35\n",
            "q_agent white win 33\n",
            "q_agent black win 33\n",
            "q_agent white win 35\n",
            "opponent_agent white win 40\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 39\n",
            "q_agent white win 38\n",
            "opponent_agent white win 55\n",
            "opponent_agent black win 36\n",
            "q_agent black win 38\n",
            "draw\n",
            "opponent_agent white win 37\n",
            "q_agent white win 49\n",
            "q_agent black win 39\n",
            "q_agent white win 42\n",
            "opponent_agent white win 45\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 34\n",
            "q_agent white win 41\n",
            "opponent_agent white win 40\n",
            "opponent_agent black win 36\n",
            "draw\n",
            "q_agent white win 43\n",
            "q_agent black win 44\n",
            "opponent_agent black win 33\n",
            "q_agent black win 35\n",
            "q_agent white win 35\n",
            "opponent_agent white win 39\n",
            "q_agent white win 52\n",
            "opponent_agent white win 33\n",
            "q_agent white win 46\n",
            "opponent_agent white win 42\n",
            "q_agent white win 45\n",
            "q_agent black win 39\n",
            "opponent_agent black win 40\n",
            "opponent_agent white win 42\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 38\n",
            "opponent_agent black win 44\n",
            "opponent_agent white win 35\n",
            "opponent_agent black win 38\n",
            "q_agent black win 42\n",
            "opponent_agent black win 35\n",
            "draw\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 46\n",
            "q_agent white win 39\n",
            "q_agent black win 33\n",
            "opponent_agent black win 53\n",
            "q_agent black win 45\n",
            "draw\n",
            "q_agent black win 39\n",
            "q_agent white win 54\n",
            "opponent_agent white win 40\n",
            "q_agent white win 34\n",
            "q_agent black win 38\n",
            "opponent_agent black win 49\n",
            "draw\n",
            "q_agent white win 36\n",
            "opponent_agent white win 38\n",
            "q_agent white win 35\n",
            "q_agent black win 37\n",
            "opponent_agent black win 36\n",
            "q_agent black win 33\n",
            "opponent_agent black win 42\n",
            "opponent_agent white win 48\n",
            "q_agent white win 43\n",
            "q_agent black win 36\n",
            "q_agent white win 40\n",
            "opponent_agent white win 44\n",
            "opponent_agent black win 39\n",
            "opponent_agent white win 43\n",
            "q_agent white win 39\n",
            "q_agent black win 37\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 36\n",
            "q_agent white win 33\n",
            "opponent_agent white win 35\n",
            "opponent_agent black win 36\n",
            "q_agent black win 37\n",
            "q_agent white win 41\n",
            "q_agent black win 43\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 33\n",
            "q_agent white win 42\n",
            "q_agent black win 44\n",
            "q_agent white win 36\n",
            "opponent_agent white win 47\n",
            "q_agent white win 42\n",
            "q_agent black win 34\n",
            "q_agent white win 39\n",
            "opponent_agent white win 33\n",
            "q_agent white win 35\n",
            "opponent_agent white win 41\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 39\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 33\n",
            "q_agent white win 44\n",
            "draw\n",
            "draw\n",
            "q_agent black win 39\n",
            "opponent_agent black win 33\n",
            "q_agent black win 36\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 36\n",
            "q_agent white win 35\n",
            "opponent_agent white win 36\n",
            "opponent_agent black win 38\n",
            "q_agent black win 37\n",
            "q_agent white win 47\n",
            "opponent_agent white win 43\n",
            "draw\n",
            "q_agent black win 40\n",
            "q_agent white win 33\n",
            "q_agent black win 40\n",
            "opponent_agent black win 40\n",
            "opponent_agent white win 48\n",
            "opponent_agent black win 38\n",
            "q_agent black win 44\n",
            "opponent_agent black win 42\n",
            "opponent_agent white win 33\n",
            "q_agent white win 48\n",
            "opponent_agent white win 36\n",
            "q_agent white win 36\n",
            "opponent_agent white win 42\n",
            "opponent_agent black win 41\n",
            "opponent_agent white win 51\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 38\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 42\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 36\n",
            "q_agent white win 38\n",
            "opponent_agent white win 35\n",
            "q_agent white win 33\n",
            "q_agent black win 33\n",
            "opponent_agent black win 39\n",
            "q_agent black win 34\n",
            "q_agent white win 44\n",
            "opponent_agent white win 34\n",
            "q_agent white win 47\n",
            "q_agent black win 53\n",
            "opponent_agent black win 35\n",
            "q_agent black win 38\n",
            "q_agent white win 36\n",
            "q_agent black win 36\n",
            "opponent_agent black win 41\n",
            "opponent_agent white win 47\n",
            "opponent_agent black win 46\n",
            "opponent_agent white win 46\n",
            "q_agent white win 41\n",
            "q_agent black win 37\n",
            "opponent_agent black win 33\n",
            "q_agent black win 33\n",
            "opponent_agent black win 33\n",
            "opponent_agent white win 40\n",
            "q_agent white win 38\n",
            "q_agent black win 47\n",
            "opponent_agent black win 39\n",
            "q_agent black win 34\n",
            "q_agent white win 33\n",
            "opponent_agent white win 43\n",
            "opponent_agent black win 36\n",
            "opponent_agent white win 35\n",
            "q_agent white win 42\n",
            "opponent_agent white win 37\n",
            "opponent_agent black win 44\n",
            "opponent_agent white win 41\n",
            "opponent_agent black win 44\n",
            "opponent_agent white win 36\n",
            "opponent_agent black win 43\n",
            "opponent_agent white win 45\n",
            "q_agent white win 33\n",
            "opponent_agent white win 35\n",
            "q_agent white win 37\n",
            "opponent_agent white win 47\n",
            "opponent_agent black win 34\n",
            "q_agent black win 35\n",
            "q_agent white win 49\n",
            "opponent_agent white win 38\n",
            "draw\n",
            "opponent_agent white win 39\n",
            "q_agent white win 46\n",
            "opponent_agent white win 41\n",
            "q_agent white win 41\n",
            "opponent_agent white win 39\n",
            "q_agent white win 43\n",
            "q_agent black win 33\n",
            "opponent_agent black win 33\n",
            "q_agent black win 44\n",
            "opponent_agent black win 35\n",
            "opponent_agent white win 33\n",
            "opponent_agent black win 45\n",
            "opponent_agent white win 47\n",
            "q_agent white win 44\n",
            "opponent_agent white win 37\n",
            "q_agent white win 33\n",
            "opponent_agent white win 39\n",
            "q_agent white win 41\n",
            "opponent_agent white win 42\n",
            "q_agent white win 49\n",
            "opponent_agent white win 44\n",
            "q_agent white win 37\n",
            "q_agent black win 43\n",
            "q_agent white win 52\n",
            "q_agent black win 35\n",
            "q_agent white win 36\n",
            "opponent_agent white win 48\n",
            "opponent_agent black win 42\n",
            "opponent_agent white win 40\n",
            "q_agent white win 36\n",
            "opponent_agent white win 37\n",
            "q_agent white win 35\n",
            "opponent_agent white win 38\n",
            "q_agent white win 37\n",
            "q_agent black win 39\n",
            "q_agent white win 40\n",
            "q_agent black win 36\n",
            "opponent_agent black win 38\n",
            "q_agent black win 39\n",
            "q_agent white win 34\n",
            "opponent_agent white win 46\n",
            "q_agent white win 34\n",
            "q_agent black win 39\n",
            "q_agent white win 40\n",
            "opponent_agent white win 38\n",
            "draw\n",
            "opponent_agent white win 49\n",
            "opponent_agent black win 39\n",
            "opponent_agent white win 41\n",
            "q_agent white win 36\n",
            "opponent_agent white win 33\n",
            "q_agent white win 41\n",
            "opponent_agent white win 42\n",
            "opponent_agent black win 43\n",
            "opponent_agent white win 41\n",
            "q_agent white win 40\n",
            "opponent_agent white win 37\n",
            "q_agent white win 37\n",
            "opponent_agent white win 33\n",
            "opponent_agent black win 39\n",
            "opponent_agent white win 44\n",
            "q_agent white win 47\n",
            "q_agent black win 34\n",
            "opponent_agent black win 34\n",
            "q_agent black win 43\n",
            "opponent_agent black win 50\n",
            "opponent_agent white win 36\n",
            "draw\n",
            "opponent_agent white win 35\n",
            "draw\n",
            "q_agent black win 33\n",
            "opponent_agent black win 37\n",
            "q_agent black win 38\n",
            "opponent_agent black win 34\n",
            "q_agent black win 51\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 36\n",
            "q_agent white win 39\n",
            "q_agent black win 40\n",
            "q_agent white win 37\n",
            "opponent_agent white win 47\n",
            "q_agent white win 37\n",
            "opponent_agent white win 36\n",
            "q_agent white win 43\n",
            "q_agent black win 38\n",
            "opponent_agent black win 42\n",
            "q_agent black win 36\n",
            "q_agent white win 39\n",
            "opponent_agent white win 45\n",
            "opponent_agent black win 33\n",
            "q_agent black win 39\n",
            "q_agent white win 33\n",
            "opponent_agent white win 34\n",
            "q_agent white win 38\n",
            "q_agent black win 35\n",
            "opponent_agent black win 34\n",
            "q_agent black win 37\n",
            "q_agent white win 43\n",
            "q_agent black win 33\n",
            "opponent_agent black win 45\n",
            "q_agent black win 33\n",
            "opponent_agent black win 33\n",
            "q_agent black win 35\n",
            "opponent_agent black win 39\n",
            "opponent_agent white win 36\n",
            "opponent_agent black win 35\n",
            "q_agent black win 36\n",
            "draw\n",
            "q_agent black win 48\n",
            "opponent_agent black win 34\n",
            "q_agent black win 38\n",
            "q_agent white win 41\n",
            "q_agent black win 33\n",
            "opponent_agent black win 38\n",
            "opponent_agent white win 46\n",
            "q_agent white win 39\n"
          ]
        }
      ],
      "source": [
        "round = 500\n",
        "for i in range(round):\n",
        "  board = creversi.Board()\n",
        "  result = play_game(q_agent, opponent_agent, board, True)\n",
        "  if result == 1:\n",
        "    q_agentcount += 1\n",
        "  elif result == 2:\n",
        "    opponent_agentcount += 1\n",
        "  board = creversi.Board()\n",
        "  result = play_game(q_agent, opponent_agent, board, False)\n",
        "  if result == 1:\n",
        "    q_agentcount += 1\n",
        "  elif result == 2:\n",
        "    opponent_agentcount += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCBFiL7dTiC8",
        "outputId": "a4c28cd5-9ab2-421f-edb8-af6904e4c330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "q_agent win 451\n",
            "opponent_agent win 511\n",
            "draw 38\n"
          ]
        }
      ],
      "source": [
        "print(\"q_agent win\", q_agentcount)\n",
        "print(\"opponent_agent win\", opponent_agentcount)\n",
        "print(\"draw\", round * 2 - q_agentcount - opponent_agentcount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0QdCpvfXA18",
        "outputId": "3e0e512d-52ae-43a8-ad95-fcf441636cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "q_agent winrate 0.451\n",
            "opponent_agent winrate 0.511\n"
          ]
        }
      ],
      "source": [
        "print(\"q_agent winrate\", q_agentcount / (round * 2))\n",
        "print(\"opponent_agent winrate\", opponent_agentcount / (round * 2))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
